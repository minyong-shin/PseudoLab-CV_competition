{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "id": "MGFHXwLL3H0c",
    "outputId": "3d8e0546-6136-442e-fb18-8b19574457bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations==0.4.6\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/33/1c459c2c9a4028ec75527eff88bc4e2d256555189f42af4baf4d7bd89233/albumentations-0.4.6.tar.gz (117kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 9.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (1.18.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
      "Collecting imgaug>=0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n",
      "\u001b[K     |████████████████████████████████| 952kB 19.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (3.13)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.0.0)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.7.1)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.16.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.10.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.5)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (4.4.2)\n",
      "Building wheels for collected packages: albumentations\n",
      "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for albumentations: filename=albumentations-0.4.6-cp36-none-any.whl size=65165 sha256=4abfed651f9d67e035e15c08a6e0fd4b8bb94fb154463dee985c58b98cdb7a35\n",
      "  Stored in directory: /root/.cache/pip/wheels/c7/f4/89/56d1bee5c421c36c1a951eeb4adcc32fbb82f5344c086efa14\n",
      "Successfully built albumentations\n",
      "Installing collected packages: imgaug, albumentations\n",
      "  Found existing installation: imgaug 0.2.9\n",
      "    Uninstalling imgaug-0.2.9:\n",
      "      Successfully uninstalled imgaug-0.2.9\n",
      "  Found existing installation: albumentations 0.1.12\n",
      "    Uninstalling albumentations-0.1.12:\n",
      "      Successfully uninstalled albumentations-0.1.12\n",
      "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "albumentations",
         "imgaug"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install albumentations==0.4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "by2W2BRX4szT",
    "outputId": "a6feab51-c746-4b33-bd7a-4148dbb4bc61"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-89f2a1e89ebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'value' is not defined"
     ]
    }
   ],
   "source": [
    "if value <= 0:\n",
    "    value = int(0)\n",
    "elif value >= 1:\n",
    "    value = int(1)\n",
    "else:\n",
    "    value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "TU2tJF-gc_kw",
    "outputId": "e471e02f-0e97-497c-e763-ce34bca6199a"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3139e28404bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# !pip freeze | grep albumentations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# !pip install albumentations==0.4.6 -> albumentations버전을 해당 버전으로 맞춰줘야함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malbumentations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToTensorV2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ToTensorV2'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List\n",
    "import math\n",
    "from glob import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pandas import json_normalize\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "# !pip freeze | grep albumentations\n",
    "# !pip install albumentations==0.4.6 -> albumentations버전을 해당 버전으로 맞춰줘야함\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "\n",
    "rootfolder = '/content/drive/My Drive/dacon - 위성 객체 인식/위성객체폴더'\n",
    "DIR_TRAIN = os.path.join(rootfolder,'train/images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNA5gL8MRC9X"
   },
   "source": [
    "# geo to coco 변환 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOEs8hyyRFdr"
   },
   "outputs": [],
   "source": [
    "# 메타 데이터 정의\n",
    "\n",
    "NIA_CLASSES = ['background', '소형 선박', '대형 선박', '민간 항공기', '군용 항공기', '소형 승용차', '버스', '트럭', '기차', '크레인', '다리', '정유탱크',\n",
    "               '댐', '운동경기장', '헬리패드', '원형 교차로']\n",
    "CLASS_NAMES_EN = ('background', 'small ship', 'large ship', 'civilian aircraft', 'military aircraft', 'small car', 'bus', 'truck', 'train',\n",
    "        'crane', 'bridge', 'oil tank', 'dam', 'athletic field', 'helipad', 'roundabout')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLCA1MIaSFCK"
   },
   "outputs": [],
   "source": [
    "# xywha 좌표계를 x,y로 변환하는 함수 정의\n",
    "def convert_xywha_to_8coords(xywha, is_clockwise=False):\n",
    "    x, y, w, h, a = xywha\n",
    "    angle = a if is_clockwise else -a\n",
    "\n",
    "    lt_x, lt_y = -w / 2, -h / 2\n",
    "    rt_x, rt_y = w / 2, - h/ 2\n",
    "    rb_x, rb_y = w / 2, h / 2\n",
    "    lb_x, lb_y = - w / 2, h / 2\n",
    "\n",
    "    lt_x_ = lt_x * math.cos(angle) - lt_y * math.sin(angle) + x\n",
    "    lt_y_ = lt_x * math.sin(angle) + lt_y * math.cos(angle) + y\n",
    "    rt_x_ = rt_x * math.cos(angle) - rt_y * math.sin(angle) + x\n",
    "    rt_y_ = rt_x * math.sin(angle) + rt_y * math.cos(angle) + y\n",
    "    lb_x_ = lb_x * math.cos(angle) - lb_y * math.sin(angle) + x\n",
    "    lb_y_ = lb_x * math.sin(angle) + lb_y * math.cos(angle) + y\n",
    "    rb_x_ = rb_x * math.cos(angle) - rb_y * math.sin(angle) + x\n",
    "    rb_y_ = rb_x * math.sin(angle) + rb_y * math.cos(angle) + y\n",
    "\n",
    "    return [lt_x_, lt_y_, rt_x_, rt_y_, rb_x_, rb_y_, lb_x_, lb_y_]\n",
    "\n",
    "\n",
    "# x,y좌표계를 coco 데이터 포멧으로 변환하는 함수\n",
    "def convert_8coords_to_4coords(coords):\n",
    "    x_coords = coords[0::2]\n",
    "    y_coords = coords[1::2]\n",
    "    \n",
    "    xmin = min(x_coords)\n",
    "    ymin = min(y_coords)\n",
    "\n",
    "    xmax = max(x_coords)\n",
    "    ymax = max(y_coords)\n",
    "\n",
    "    w = xmax-xmin\n",
    "    h = ymax-ymin\n",
    "\n",
    "    return [xmin, ymin, w, h]\n",
    "\n",
    "# json 파일에서 필요한 정보를 불러오는 함수\n",
    "\n",
    "def convert_labels_to_objects(coords, class_ids, class_names, image_ids, difficult=0, is_clockwise=False):\n",
    "    objs = list()\n",
    "    inst_count = 1\n",
    "\n",
    "    for polygons, cls_id, cls_name, img_id in tqdm(zip(coords, class_ids, class_names, image_ids), desc=\"converting labels to objects\"):\n",
    "        xmin, ymin, w, h = convert_8coords_to_4coords(polygons)\n",
    "        single_obj = {}\n",
    "        single_obj['difficult'] = difficult\n",
    "        single_obj['area'] = w*h\n",
    "        if cls_name in CLASS_NAMES_EN:\n",
    "            single_obj['category_id'] = CLASS_NAMES_EN.index(cls_name)\n",
    "        else:\n",
    "            continue\n",
    "        single_obj['segmentation'] = [[int(p) for p in polygons]]\n",
    "        single_obj['iscrowd'] = 0\n",
    "        single_obj['bbox'] = (xmin, ymin, w, h)\n",
    "        single_obj['image_id'] = img_id\n",
    "        single_obj['id'] = inst_count\n",
    "        inst_count += 1\n",
    "        objs.append(single_obj)\n",
    "\n",
    "    print('objects', len(objs))\n",
    "    return objs\n",
    "\n",
    "# geojson파일을 불러오는 함수\n",
    "def load_geojsons(filepath):\n",
    "    \"\"\" Gets label data from a geojson label file\n",
    "\n",
    "    :param (str) filename: file path to a geojson label file\n",
    "    :return: (numpy.ndarray, numpy.ndarray ,numpy.ndarray) coords, chips, and classes corresponding to\n",
    "            the coordinates, image names, and class codes for each ground truth.\n",
    "    \"\"\"\n",
    "    jsons = glob(os.path.join(filepath, '*.json'))\n",
    "    features = []\n",
    "    for json_path in tqdm(jsons, desc='loading geojson files'):\n",
    "        with open(json_path) as f:\n",
    "            data_dict = json.load(f)\n",
    "        features += data_dict['features']\n",
    "\n",
    "    obj_coords = list()\n",
    "    image_ids = list()\n",
    "    class_indices = list()\n",
    "    class_names = list()\n",
    "\n",
    "    for feature in tqdm(features, desc='extracting features'):\n",
    "        properties = feature['properties']\n",
    "        image_ids.append(properties['image_id'].replace('PS4', 'PS3')[:-4]+'.png')\n",
    "        obj_coords.append([float(num) for num in properties['object_imcoords'].split(\",\")])\n",
    "        class_indices.append(properties['type_id'])\n",
    "        class_names.append(properties['type_name'])\n",
    "\n",
    "    return image_ids, obj_coords, class_indices, class_names\n",
    "\n",
    "# coco변환 함수\n",
    "\n",
    "def geojson2coco(imageroot: str, geojsonpath: str, destfile, difficult='-1'):\n",
    "    # set difficult to filter '2', '1', or do not filter, set '-1'\n",
    "\n",
    "    data_dict = {}\n",
    "    data_dict['images'] = []\n",
    "    data_dict['categories'] = []\n",
    "    data_dict['annotations'] = []\n",
    "    for idex, name in enumerate(CLASS_NAMES_EN):\n",
    "        single_cat = {'id': idex + 1, 'name': name, 'supercategory': name}\n",
    "        data_dict['categories'].append(single_cat)\n",
    "\n",
    "    inst_count = 1\n",
    "    image_id = 1\n",
    "    with open(destfile, 'w') as f_out:\n",
    "      \n",
    "        img_files, obj_coords, cls_ids, class_names = load_geojsons(geojsonpath)\n",
    "        img_id_map= {img_file:i+1 for i, img_file in enumerate(list(set(img_files)))}\n",
    "        image_ids = [img_id_map[img_file] for img_file in img_files]\n",
    "\n",
    "        objs = convert_labels_to_objects(obj_coords, cls_ids, class_names, image_ids, difficult=difficult, is_clockwise=False)\n",
    "        data_dict['annotations'].extend(objs)\n",
    "\n",
    "        for imgfile in tqdm(img_id_map, desc='saving img info'):\n",
    "            imagepath = os.path.join(imageroot, imgfile)\n",
    "            img_id = img_id_map[imgfile]\n",
    "            img = cv2.imread(imagepath)\n",
    "            height, width, c = img.shape\n",
    "            single_image = {}\n",
    "            single_image['file_name'] = imgfile\n",
    "            single_image['id'] = img_id\n",
    "            single_image['width'] = width\n",
    "            single_image['height'] = height\n",
    "            single_image['image_name'] = imgfile\n",
    "            data_dict['images'].append(single_image)\n",
    "\n",
    "        json.dump(data_dict, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "sm8OZ1ngS_qp",
    "outputId": "ba895dfc-eccc-4d24-9abe-f8b94f9928dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading geojson files:   5%|▍         | 38/800 [00:17<04:54,  2.58it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-97a75367a1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m geojson2coco(imageroot=os.path.join(rootfolder, 'train/images'),\n\u001b[1;32m      5\u001b[0m                  \u001b[0mgeojsonpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train/json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                  destfile=os.path.join(rootfolder, 'coco_format/traincoco.json'))\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# geojson2coco(imageroot=os.path.join(rootfolder, 'val/images'),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-78555a7dafe9>\u001b[0m in \u001b[0;36mgeojson2coco\u001b[0;34m(imageroot, geojsonpath, destfile, difficult)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mimg_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_coords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_geojsons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeojsonpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mimg_id_map\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mimg_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mimage_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg_id_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_file\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-78555a7dafe9>\u001b[0m in \u001b[0;36mload_geojsons\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mjson_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loading geojson files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \"\"\"\n\u001b[0;32m--> 296\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 정제하는 과정에서 bbox값이 5개가 들어가는 경우가 있음\n",
    "rootfolder = '/content/drive/My Drive/dacon - 위성 객체 인식/위성객체폴더'\n",
    "\n",
    "geojson2coco(imageroot=os.path.join(rootfolder, 'train/images'),\n",
    "                 geojsonpath=os.path.join(rootfolder, 'train/json'),\n",
    "                 destfile=os.path.join(rootfolder, 'coco_format/traincoco.json'))\n",
    "    \n",
    "# geojson2coco(imageroot=os.path.join(rootfolder, 'val/images'),\n",
    "#                  geojsonpath=os.path.join(rootfolder, 'val/json'),\n",
    "#                  destfile=os.path.join(rootfolder, 'val/valcoco.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ChqntxOpUMaC"
   },
   "source": [
    "# 저장한 Json 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "id": "9SPQdguDdQeb",
    "outputId": "a7942dad-c18b-4434-adb0-7de8687baa8b"
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3e5bae6dff3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'coco_format/traincoco.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjs_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mjson_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjs_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcoco_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_normalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 354\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \"\"\"\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(rootfolder,'coco_format/traincoco.json')) as js_file:\n",
    "\n",
    "  json_data = json.load(js_file)\n",
    "\n",
    "coco_df = json_normalize(json_data['annotations'])\n",
    "\n",
    "# 이미지 이름(파일 이름) 불러오는 부분\n",
    "image_id_df = pd.DataFrame()\n",
    "file_name = []\n",
    "id_ls = []\n",
    "for file_nm in json_data['images']:\n",
    "  file_name.append(file_nm.get('file_name'))\n",
    "  id_ls.append(file_nm.get('id'))\n",
    "\n",
    "image_id_df['image_id'] = id_ls\n",
    "image_id_df['image_name'] = file_name\n",
    "\n",
    "coco_df = pd.merge(coco_df,image_id_df, on = 'image_id',how = 'left')\n",
    "\n",
    "# # 데이터 저장\n",
    "# coco_df.to_csv(f'{rootfolder}/coco_format/cocodata_format.csv',index = False)\n",
    "\n",
    "# coco_df = pd.read_csv(os.path.join(rootfolder, 'coco_format/cocodata_format.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "MFTvcVCWe9t0",
    "outputId": "b153bfb5-d2bb-4303-9f4b-4b982bd6f8f2"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b26660caaa10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcoco_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'coco_df' is not defined"
     ]
    }
   ],
   "source": [
    "coco_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdXsYwpKQ1v4"
   },
   "outputs": [],
   "source": [
    "# 학습할 데이터 형태로 추출\n",
    "coco_df2 = coco_df[['image_name','segmentation','category_id','bbox']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4EsXpMoQlCT"
   },
   "source": [
    "# coco dataset bbox 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7jHoqBzPKLp"
   },
   "outputs": [],
   "source": [
    "coco_df2['x'] = -1\n",
    "coco_df2['y'] = -1\n",
    "coco_df2['w'] = -1\n",
    "coco_df2['h'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kMpbb7huTcPX"
   },
   "outputs": [],
   "source": [
    "# def string_to_list_convert(x):\n",
    "#   ls = np.array(re.findall('([0-9]+[.]?[0-9]*)',x))\n",
    "\n",
    "#   if len(ls) == 0:\n",
    "#         ls = [-1, -1, -1, -1]\n",
    "#   return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImUzBDsTRMVV"
   },
   "outputs": [],
   "source": [
    "coco_df2['bbox_len'] = coco_df2['bbox'].apply(lambda x: len(x))\n",
    "\n",
    "coco_df3 = coco_df2[coco_df2['bbox_len'] == 4]\n",
    "\n",
    "coco_df3[['x','y','w','h']] = np.stack(coco_df3['bbox'])\n",
    "\n",
    "coco_df3['x'] = coco_df3['x'].astype(np.float)\n",
    "coco_df3['y'] = coco_df3['y'].astype(np.float)\n",
    "coco_df3['w'] = coco_df3['w'].astype(np.float)\n",
    "coco_df3['h'] = coco_df3['h'].astype(np.float)\n",
    "\n",
    "# coco_df3.drop(columns = ['bbox','bbox_len'],inplace = True)\n",
    "coco_df3.drop(columns = ['bbox_len'],inplace = True)\n",
    "# coco_df3.rename(columns = {'bbox2':'bbox'},inplace = True)\n",
    "\n",
    "coco_df3[['height','width']] = [1024,1024]\n",
    "coco_df4 = coco_df3[['image_name','width','height','category_id','x','y','w','h']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bH2XcsT9vdil"
   },
   "outputs": [],
   "source": [
    "# # 각 image_id에 맞는 사진 파일명 불러오기\n",
    "# file_name_df = pd.DataFrame()\n",
    "\n",
    "# file_name_df['image_id'] = coco_df.sort_values('image_id')['image_id'].unique().tolist()\n",
    "# file_name_df['image_id2'] = os.listdir(DIR_TRAIN)\n",
    "\n",
    "# coco_df5 = pd.merge(coco_df4,file_name_df,on='image_id',how = 'left')\n",
    "\n",
    "# coco_df5['image_id'] = coco_df5['image_id2']\n",
    "# coco_df5.drop(columns = 'image_id2',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqgvLXCuQCum"
   },
   "outputs": [],
   "source": [
    "coco_df4.rename(columns = {'image_name':'image_id'},inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtiFQb7_X3iC"
   },
   "source": [
    "# train, validset 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdv9yRtIXu0p"
   },
   "outputs": [],
   "source": [
    "img_ids = coco_df4['image_id'].unique().tolist()\n",
    "valid_ids = img_ids[int(-1*len(img_ids)*0.2):]\n",
    "train_ids = img_ids[:int(-1*len(img_ids)*0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GgEPP1AwR-yK"
   },
   "outputs": [],
   "source": [
    "coco_train = coco_df4[\n",
    "                      coco_df4['image_id'].isin(train_ids)\n",
    "                      ]\n",
    "coco_valid = coco_df4[\n",
    "                      coco_df4['image_id'].isin(valid_ids)\n",
    "                      ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53BPzXWvaepm"
   },
   "outputs": [],
   "source": [
    "len(coco_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KTVrlB4VjGPH"
   },
   "outputs": [],
   "source": [
    "coco_train['category_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rK-jRqTE1OeK"
   },
   "source": [
    "# 샘플로 Bbox 도식화 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9KkcNbU91R4R"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootfolder,'train/images/OBJ03589_PS3_K3A_NIA0151.png') , cv2.COLOR_BGR2RGB)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#plt.figure(figsize = (16,16)) #용량 문제로 주석 처리\n",
    "plt.imshow(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxYtM1-sT2mo"
   },
   "outputs": [],
   "source": [
    "sample_box = coco_train[coco_train['image_id'] == 'OBJ03589_PS3_K3A_NIA0151.png'][['x','y','w','h']].iloc[0].tolist()\n",
    "sample_box2 = [sample_box[0],sample_box[1],sample_box[0] + sample_box[2],sample_box[1] + sample_box[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVpVABzx2Sop"
   },
   "outputs": [],
   "source": [
    "cv2.rectangle(img,\n",
    "              (int(sample_box2[0]), int(sample_box2[1])),\n",
    "              (int(sample_box2[2]), int(sample_box2[3])),\n",
    "              (220, 0, 0), 3)\n",
    "\n",
    "plt.figure(figsize = (16,16))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDaUVB-Na8tR"
   },
   "source": [
    "# torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmYNBR3zuRDY"
   },
   "outputs": [],
   "source": [
    "# 에러나온 부분 해결하는 코드\n",
    "\n",
    "# next(iter(train_data_loader))\n",
    "\n",
    "# for i in range(0,500):\n",
    "#   print(i)\n",
    "#   image_id = img_ids[i]\n",
    "#   records = coco_train[coco_train['image_id'] == image_id]\n",
    "\n",
    "#   image = cv2.imread(f'{DIR_TRAIN}/{image_id}', cv2.IMREAD_COLOR)\n",
    "#   image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "#   image /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZuiPNE8ir2N"
   },
   "outputs": [],
   "source": [
    "# 이거 코드 뜯어보자\n",
    "class WheatDataset(Dataset):\n",
    "\n",
    "    # 데이터를 로드하는 부분\n",
    "    def __init__(self, dataframe, image_dir, transforms=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_ids = dataframe['image_id'].unique()\n",
    "        self.df = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transforms = transforms\n",
    "\n",
    "    # dataloader에 필요한 값으로 정리가 됨\n",
    "    # 로드한 data를 차례차례 돌려주는 역할\n",
    "    def __getitem__(self, index: int):\n",
    "\n",
    "        try:\n",
    "          print(index)\n",
    "          image_id = self.image_ids[index]\n",
    "          records = self.df[self.df['image_id'] == image_id]\n",
    "\n",
    "          image = cv2.imread(f'{self.image_dir}/{image_id}', cv2.IMREAD_COLOR)\n",
    "          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "          image /= 255.0\n",
    "          \n",
    "          \n",
    "          boxes = records[['x', 'y', 'w', 'h']].values\n",
    "          boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "          boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "          \n",
    "          area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "          area = torch.as_tensor(area, dtype=torch.float32)\n",
    "\n",
    "          # there is only one class\n",
    "          labels = torch.ones((records.shape[0],), dtype=torch.int64)\n",
    "          \n",
    "          # suppose all instances are not crowd\n",
    "          iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n",
    "          \n",
    "          target = {}\n",
    "          target['boxes'] = boxes\n",
    "          target['labels'] = labels\n",
    "          # target['masks'] = None\n",
    "          target['image_id'] = torch.tensor([index])\n",
    "          target['area'] = area\n",
    "          target['iscrowd'] = iscrowd\n",
    "\n",
    "          if self.transforms:\n",
    "              sample = {\n",
    "                  'image': image,\n",
    "                  'bboxes': target['boxes'],\n",
    "                  'labels': labels\n",
    "              }\n",
    "              sample = self.transforms(**sample)\n",
    "              image = sample['image']\n",
    "              \n",
    "              target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "              #target['boxes'] = target['boxes'].type(torch.float32)\n",
    "          return image, target, image_id\n",
    "        except:\n",
    "          pass\n",
    "\n",
    "    # 전체 데이터 길이를 계산함\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iz2VSHujiwRP"
   },
   "outputs": [],
   "source": [
    "# Albumentations\n",
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Flip(0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "def get_valid_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeEdtAKei73w"
   },
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTu-iSxfjBIs"
   },
   "outputs": [],
   "source": [
    "# load a model; pre-trained on COCO -> 이미지넷으로 학습된 코코에서 faster rcnn 모델 불러옴\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HF6dkQqUjBcr"
   },
   "outputs": [],
   "source": [
    "num_classes =   16 # 1 class (wheat) + background -> 밀과 배경을 구분하기 위해서 class + 1을 클래스 분류 값으로 넣어줌\n",
    "\n",
    "# get number of input features for the classifier\n",
    "# 이게 왜 필요한거지?\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tP60SCnhjOgD"
   },
   "outputs": [],
   "source": [
    "class Averager:\n",
    "    def __init__(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0\n",
    "\n",
    "    def send(self, value):\n",
    "        self.current_total += value\n",
    "        self.iterations += 1\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        if self.iterations == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0 * self.current_total / self.iterations\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_total = 0.0\n",
    "        self.iterations = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcOm63gOjQyR"
   },
   "outputs": [],
   "source": [
    "# 배치사이즈 튜플화?\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuvPT_MkjSTo"
   },
   "outputs": [],
   "source": [
    "def __init__(self, dataframe, image_dir, transforms=None):\n",
    "    super().__init__()\n",
    "\n",
    "    self.image_ids = dataframe['image_id'].unique()\n",
    "    self.df = dataframe\n",
    "    self.image_dir = image_dir\n",
    "    self.transforms = transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKVwmHtZixyi"
   },
   "outputs": [],
   "source": [
    "# # 18번 인덱스까지만 뽑아서 해보자\n",
    "# coco_train2 = pd.DataFrame()\n",
    "\n",
    "# for i in image_ids[:18]:\n",
    "#   coco_train2 = coco_train2.append(coco_train[coco_train['image_id'] == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nz7d3DzPo6Pm"
   },
   "outputs": [],
   "source": [
    "coco_train2 = coco_train[\n",
    "           (coco_train['x'] >= 0) \n",
    "           & (coco_train['y'] >= 0)\n",
    "           ]\n",
    "\n",
    "coco_valid2 = coco_valid[\n",
    "           (coco_valid['x'] >= 0) \n",
    "           & (coco_valid['y'] >= 0)\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-EoVljlkCEN"
   },
   "outputs": [],
   "source": [
    "# 이미지 파일 위치하는 경로\n",
    "\n",
    "DIR_TRAIN = os.path.join(rootfolder,'train/images')\n",
    "\n",
    "# train_dataset = WheatDataset(coco_train, DIR_TRAIN, get_train_transform())\n",
    "# valid_dataset = WheatDataset(coco_valid, DIR_TRAIN, get_valid_transform())\n",
    "\n",
    "train_dataset = WheatDataset(coco_train2, DIR_TRAIN, get_train_transform())\n",
    "valid_dataset = WheatDataset(coco_valid2, DIR_TRAIN, get_valid_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WwB-mtjkkkn"
   },
   "outputs": [],
   "source": [
    "# split the dataset in train and test set\n",
    "indices = torch.randperm(len(train_dataset)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QvBs_d60sYac"
   },
   "outputs": [],
   "source": [
    "# batch_size=12,\n",
    "# bounding box의 xmin, ymin이 음수이면 안됨\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "valid_data_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DUtm8PJsZBa"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wx0Wk0tptlvT"
   },
   "source": [
    "# 샘플 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uz-7GaEGZPum"
   },
   "outputs": [],
   "source": [
    "test = iter(train_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tapZsavLZzpr"
   },
   "outputs": [],
   "source": [
    "n = 0\n",
    "while True:\n",
    "  # try:\n",
    "  #   print(n)\n",
    "  print(n)\n",
    "  it_test = iter(train_data_loader)\n",
    "  images, targets, image_ids = next(it_test)\n",
    "  print(images, targets, image_ids)\n",
    "  images = list(image.to(device) for image in images)\n",
    "  targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "  boxes = targets[1]['boxes'].cpu().numpy().astype(np.int32)\n",
    "  sample = images[1].permute(1,2,0).cpu().numpy()\n",
    "\n",
    "  \n",
    "  n += 1\n",
    "  # except:\n",
    "  #   print(n)\n",
    "  #   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_EbAE4atpvx"
   },
   "outputs": [],
   "source": [
    "images, targets, image_ids = next(iter(train_data_loader))\n",
    "\n",
    "images = list(image.to(device) for image in images)\n",
    "targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "boxes = targets[1]['boxes'].cpu().numpy().astype(np.int32)\n",
    "sample = images[1].permute(1,2,0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7q6p6ZpDfeBB"
   },
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sFrfyP6AfUv_"
   },
   "outputs": [],
   "source": [
    "len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbeHouJBeJ0K"
   },
   "outputs": [],
   "source": [
    "len(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5V9klpadzsH"
   },
   "outputs": [],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "racLU83q0Ryz"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "for box in boxes:\n",
    "    cv2.rectangle(sample,\n",
    "                  (box[0], box[1]),\n",
    "                  (box[2], box[3]),\n",
    "                  (220, 0, 0), 3)\n",
    "    \n",
    "ax.set_axis_off()\n",
    "ax.imshow(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDKA7P62-SjH"
   },
   "source": [
    "# 최종학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wh1Y55pltqkT"
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "lr_scheduler = None\n",
    "\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ElWj5hvtw1p"
   },
   "outputs": [],
   "source": [
    "loss_hist = Averager()\n",
    "itr = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_hist.reset()\n",
    "    print(epoch)\n",
    "\n",
    "    # it_test = iter(train_data_loader) \n",
    "    # n = 0\n",
    "    # while True:\n",
    "\n",
    "        #try:\n",
    "    for images, targets, image_ids in train_data_loader:\n",
    "      # print(n)\n",
    "      # images, targets, image_ids = next(it_test)\n",
    "      # print(images)\n",
    "      images = list(image.to(device) for image in images)\n",
    "      # targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "      targets = [{k: v.long().to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "\n",
    "      loss_dict = model(images, targets)\n",
    "\n",
    "      losses = sum(loss for loss in loss_dict.values())\n",
    "      loss_value = losses.item()\n",
    "\n",
    "      loss_hist.send(loss_value)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      losses.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if itr % 50 == 0:\n",
    "          print(f\"Iteration #{itr} loss: {loss_value}\")\n",
    "\n",
    "      itr += 1\n",
    "      # n += 1\n",
    "        # except:\n",
    "        #   print('학습 끝')\n",
    "        #   break\n",
    "    \n",
    "    # update the learning rate\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    print(f\"Epoch #{epoch} loss: {loss_hist.value}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yK8zEVQoxBIc"
   },
   "outputs": [],
   "source": [
    "loss_hist = Averager()\n",
    "itr = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_hist.reset()\n",
    "    print(epoch)\n",
    "\n",
    "    # it_test = iter(train_data_loader) \n",
    "    # n = 0\n",
    "    # while True:\n",
    "\n",
    "        #try:\n",
    "    for images, targets, image_ids in train_data_loader:\n",
    "      # print(n)\n",
    "      # images, targets, image_ids = next(it_test)\n",
    "      # print(images)\n",
    "      images = list(image.to(device) for image in images)\n",
    "      # targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "      targets = [{k: v.long().to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "\n",
    "      loss_dict = model(images, targets)\n",
    "\n",
    "      losses = sum(loss for loss in loss_dict.values())\n",
    "      loss_value = losses.item()\n",
    "\n",
    "      loss_hist.send(loss_value)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      losses.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      if itr % 50 == 0:\n",
    "          print(f\"Iteration #{itr} loss: {loss_value}\")\n",
    "\n",
    "      itr += 1\n",
    "      # n += 1\n",
    "        # except:\n",
    "        #   print('학습 끝')\n",
    "        #   break\n",
    "    \n",
    "    # update the learning rate\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    print(f\"Epoch #{epoch} loss: {loss_hist.value}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQApidHmjpiw"
   },
   "source": [
    "# 검증셋 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bAgpxMxje74"
   },
   "outputs": [],
   "source": [
    "images, targets, image_ids = next(iter(valid_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iId1bYqTjmJc"
   },
   "outputs": [],
   "source": [
    "images = list(img.to(device) for img in images)\n",
    "targets = [{k: v.to(device) for k, v in t.items()} for t in targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YAIx0-cjnxw"
   },
   "outputs": [],
   "source": [
    "boxes = targets[1]['boxes'].cpu().numpy().astype(np.int32)\n",
    "sample = images[1].permute(1,2,0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkkhACkQjxM6"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "cpu_device = torch.device(\"cpu\")\n",
    "\n",
    "outputs = model(images)\n",
    "outputs = [{k: v.to(cpu_device) for k, v in t.items()} for t in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u60MBDJ_jxqT"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "for box in boxes:\n",
    "    cv2.rectangle(sample,\n",
    "                  (box[0], box[1]),\n",
    "                  (box[2], box[3]),\n",
    "                  (220, 0, 0), 3)\n",
    "    \n",
    "ax.set_axis_off()\n",
    "ax.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qT6yZPbIjx1q"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/content/drive/My Drive/dacon - 위성 객체 인식/위성객체폴더/fasterrcnn_resnet50_fpn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMRKrAR1X-AX"
   },
   "source": [
    "# dataloader 뜯어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UqPoVlffY8dx"
   },
   "outputs": [],
   "source": [
    "coco_train[coco_train['x'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDOeVVIHY4P7"
   },
   "outputs": [],
   "source": [
    "image_ids = coco_train2['image_id'].unique()\n",
    "df = coco_train2\n",
    "image_dir = DIR_TRAIN\n",
    "transforms = get_train_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNdN8or3hiYr"
   },
   "outputs": [],
   "source": [
    "index = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G38jCtmWsYn3"
   },
   "outputs": [],
   "source": [
    "tuple(boxes[0][4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrBTbBORsPJi"
   },
   "outputs": [],
   "source": [
    "(x_min, y_min, x_max, y_max), tail = boxes[0][:1], tuple(boxes[0][4:])\n",
    "width = x_max - x_min\n",
    "height = y_max - y_min\n",
    "bbox = (x_min, y_min, width, height) + tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vDoYdHTUYYGL"
   },
   "outputs": [],
   "source": [
    "# 변환될 때 [0,1]인 것을 어떻게 체크하지 어떻게 변환되는지 원리를 알아야 하는데\n",
    "image_id = image_ids[index]\n",
    "records = df[df['image_id'] == image_id]\n",
    "\n",
    "image = cv2.imread(f'{image_dir}/{image_id}', cv2.IMREAD_COLOR)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "image /= 255.0\n",
    "\n",
    "\n",
    "boxes = records[['x', 'y', 'w', 'h']].values\n",
    "boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "\n",
    "area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "area = torch.as_tensor(area, dtype=torch.float32)\n",
    "\n",
    "# there is only one class\n",
    "labels = torch.ones((records.shape[0],), dtype=torch.int64)\n",
    "\n",
    "# suppose all instances are not crowd\n",
    "iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n",
    "\n",
    "target = {}\n",
    "target['boxes'] = boxes\n",
    "target['labels'] = labels\n",
    "# target['masks'] = None\n",
    "target['image_id'] = torch.tensor([index])\n",
    "target['area'] = area\n",
    "target['iscrowd'] = iscrowd\n",
    "\n",
    " # 신민용 수정 -> 0과 1 이 아닌 박스는 지나치도록\n",
    "            # raise ValueError(\n",
    "            #     \"Expected {name} for bbox {bbox} \"\n",
    "            #     \"to be in the range [0.0, 1.0], got {value}.\".format(bbox=bbox, name=name, value=value)\n",
    "            # )\n",
    "if transforms:\n",
    "    sample = {\n",
    "        'image': image,\n",
    "        'bboxes': target['boxes'],\n",
    "        'labels': labels\n",
    "    }\n",
    "    sample = transforms(**sample)\n",
    "    image = sample['image']\n",
    "    \n",
    "    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "    #target['boxes'] = target['boxes'].type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sjEmGrRP0mFW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f08L7-11qbBR"
   },
   "outputs": [],
   "source": [
    "target['boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rBaxDVJny4o"
   },
   "outputs": [],
   "source": [
    "sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ngm0YHEpY3o9"
   },
   "outputs": [],
   "source": [
    "def get_train_transform():\n",
    "    return A.Compose([\n",
    "        A.Flip(0.5),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ryqVWLqznniN"
   },
   "outputs": [],
   "source": [
    "transforms(**sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P68ErXd5nouU"
   },
   "outputs": [],
   "source": [
    "transforms(**sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckdZ2dLFobjX"
   },
   "outputs": [],
   "source": [
    "coco_train2[coco_train2['h'] >= 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rmd2-6DgqsZ6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "re3KU91NvCHM"
   },
   "outputs": [],
   "source": [
    "len('000000000000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjZ-oWC8vDoi"
   },
   "outputs": [],
   "source": [
    "1.0000000000000002 == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZT0R37_ux4Cw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "위성 객체 인식.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
